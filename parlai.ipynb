{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"parlai.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1EEMoA15EoqUPVKPD8eGx9lxxckkOedvI","authorship_tag":"ABX9TyPGxSTh29QtDMg22WFfVGaF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"3w-zcg0o3FFr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620016503320,"user_tz":300,"elapsed":34776,"user":{"displayName":"Diya Li","photoUrl":"","userId":"02479113133044853042"}},"outputId":"bec5d4fe-5252-4f74-9282-5a268236226b"},"source":["!pip install -q parlai\n","!pip install wandb"],"execution_count":1,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 1.3MB 4.3MB/s \n","\u001b[K     |████████████████████████████████| 163kB 56.9MB/s \n","\u001b[K     |████████████████████████████████| 40kB 6.9MB/s \n","\u001b[K     |████████████████████████████████| 552kB 53.8MB/s \n","\u001b[K     |████████████████████████████████| 133kB 60.4MB/s \n","\u001b[K     |████████████████████████████████| 7.5MB 57.4MB/s \n","\u001b[K     |████████████████████████████████| 51kB 7.8MB/s \n","\u001b[K     |████████████████████████████████| 51kB 7.9MB/s \n","\u001b[K     |████████████████████████████████| 133kB 62.4MB/s \n","\u001b[K     |████████████████████████████████| 245kB 51.5MB/s \n","\u001b[K     |████████████████████████████████| 61kB 9.0MB/s \n","\u001b[K     |████████████████████████████████| 61kB 9.1MB/s \n","\u001b[K     |████████████████████████████████| 3.3MB 53.4MB/s \n","\u001b[K     |████████████████████████████████| 133kB 59.6MB/s \n","\u001b[K     |████████████████████████████████| 51kB 7.4MB/s \n","\u001b[K     |████████████████████████████████| 2.7MB 51.2MB/s \n","\u001b[K     |████████████████████████████████| 122kB 59.4MB/s \n","\u001b[K     |████████████████████████████████| 215kB 58.0MB/s \n","\u001b[K     |████████████████████████████████| 9.2MB 46.0MB/s \n","\u001b[K     |████████████████████████████████| 133kB 60.7MB/s \n","\u001b[K     |████████████████████████████████| 81kB 11.4MB/s \n","\u001b[K     |████████████████████████████████| 71kB 10.8MB/s \n","\u001b[K     |████████████████████████████████| 92kB 11.9MB/s \n","\u001b[K     |████████████████████████████████| 112kB 58.4MB/s \n","\u001b[K     |████████████████████████████████| 81kB 11.3MB/s \n","\u001b[K     |████████████████████████████████| 102kB 13.0MB/s \n","\u001b[K     |████████████████████████████████| 122kB 58.8MB/s \n","\u001b[K     |████████████████████████████████| 92kB 12.5MB/s \n","\u001b[K     |████████████████████████████████| 92kB 12.7MB/s \n","\u001b[K     |████████████████████████████████| 112kB 56.8MB/s \n","\u001b[K     |████████████████████████████████| 71kB 9.3MB/s \n","\u001b[K     |████████████████████████████████| 51kB 7.6MB/s \n","\u001b[?25h  Building wheel for websocket-server (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for docformatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for untokenize (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: omegaconf 2.0.6 has requirement PyYAML>=5.1.*, but you'll have pyyaml 3.13 which is incompatible.\u001b[0m\n","\u001b[31mERROR: fvcore 0.1.5.post20210423 has requirement pyyaml>=5.1, but you'll have pyyaml 3.13 which is incompatible.\u001b[0m\n","Collecting wandb\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/ee/d755f9e5466df64c8416a2c6a860fb3aaa43ed6ea8e8e8e81460fda5788b/wandb-0.10.28-py2.py3-none-any.whl (2.1MB)\n","\u001b[K     |████████████████████████████████| 2.1MB 4.0MB/s \n","\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.14)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.12.4)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n","Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Collecting configparser>=3.8.1\n","  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Collecting pathtools\n","  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n","Collecting subprocess32>=3.5.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n","\u001b[K     |████████████████████████████████| 102kB 10.4MB/s \n","\u001b[?25hCollecting shortuuid>=0.5.0\n","  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n","Collecting sentry-sdk>=0.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/92/5a33be64990ba815364a8f2dd9e6f51de60d23dfddafb4f1fc5577d4dc64/sentry_sdk-1.0.0-py2.py3-none-any.whl (131kB)\n","\u001b[K     |████████████████████████████████| 133kB 21.1MB/s \n","\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Collecting docker-pycreds>=0.4.0\n","  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.7)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb) (56.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.25.11)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2020.12.5)\n","Requirement already satisfied: smmap<5,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (4.0.0)\n","Building wheels for collected packages: pathtools, subprocess32\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-cp37-none-any.whl size=8786 sha256=42ae97afab9ea8967786075cdee0b646b1be5b9017b9836c9b16f8e1c5655439\n","  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n","  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp37-none-any.whl size=6489 sha256=6b0c625c7199be998ac54884536af21210a4a2bccd6f714fdc45b1955cc04790\n","  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n","Successfully built pathtools subprocess32\n","Installing collected packages: configparser, pathtools, subprocess32, shortuuid, sentry-sdk, docker-pycreds, wandb\n","Successfully installed configparser-5.0.2 docker-pycreds-0.4.0 pathtools-0.1.2 sentry-sdk-1.0.0 shortuuid-1.0.1 subprocess32-3.5.4 wandb-0.10.28\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fs9CPMKv5bIs","executionInfo":{"status":"ok","timestamp":1620012537192,"user_tz":300,"elapsed":34542,"user":{"displayName":"Diya Li","photoUrl":"","userId":"02479113133044853042"}},"outputId":"ce6537e7-4e56-474c-c631-e75f329ea721"},"source":["!nvidia-smi"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mon May  3 03:28:57 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qfVk2nQHkWl5"},"source":[" !pip install colab_ssh --upgrade\n","from colab_ssh import launch_ssh_cloudflared, init_git_cloudflared\n","launch_ssh_cloudflared(password=\"KG8VkPp2GyI6781GWg\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k2Riuc2a3DZS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620012566033,"user_tz":300,"elapsed":495,"user":{"displayName":"Diya Li","photoUrl":"","userId":"02479113133044853042"}},"outputId":"e6fc8883-0295-4ccb-c173-f4ba4e80e067"},"source":["working_dir = \"/content/drive/MyDrive/Dev/ECEN689/ECEN689\"\n","print(working_dir)\n","from parlai.scripts.train_model import TrainModel\n","import os \n","import numpy as np\n","import pandas as pd"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Dev/ECEN689/ECEN689\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"buL4HzAXP2Tj"},"source":["# train a fine tune model\n","# TrainModel.main(\n","#     # similar to before\n","#     task='empathetic_dialogues', \n","#     model='transformer/generator',\n","#     model_file='from_pretrained/model',\n","    \n","#     # initialize with a pretrained model\n","#     init_model='zoo:tutorial_transformer_generator/model',\n","    \n","#     # arguments we get from the pretrained model.\n","#     # Unfortunately, these must be looked up separately for each model.\n","#     n_heads=16, n_layers=8, n_positions=512, text_truncate=512,\n","#     label_truncate=128, ffn_size=2048, embedding_size=512,\n","#     activation='gelu', variant='xlm',\n","#     dict_lower=True, dict_tokenizer='bpe',\n","#     dict_file='zoo:tutorial_transformer_generator/model.dict',\n","#     learn_positional_embeddings=True,\n","    \n","#     # some training arguments, specific to this fine-tuning\n","#     # use a small learning rate with ADAM optimizer\n","#     lr=1e-5, optimizer='adam',\n","#     warmup_updates=100,\n","#     # early stopping on perplexity\n","#     validation_metric='ppl',\n","#     # train at most 10 minutes, and validate every 0.25 epochs\n","#     max_train_time=600, validation_every_n_epochs=0.25,\n","    \n","#     # depend on your gpu. If you have a V100, this is good\n","#     batchsize=12, fp16=True, fp16_impl='mem_efficient',\n","    \n","#     # speeds up validation\n","#     skip_generation=True,\n","    \n","#     # helps us cram more examples into our gpu at a time\n","#     dynamic_batching='full',\n","#     verbose=False,\n","#     wandb_log=True,\n","#     wandb_project=\"ecen689-project\"\n","# )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g0LlG2ZOM-ap"},"source":["# Import the Interactive script\n","from parlai.scripts.interactive import Interactive\n","\n","# call it with particular args\n","Interactive.main(\n","    model_file=os.path.join(working_dir, \"from_pretrained/model\"),\n","    # model_file='zoo:dodecadialogue/empathetic_dialogues_ft/model',\n","    inference=\"beam\", \n","    beam_size=5, beam_min_length=10, beam_block_ngram=3, beam_context_block_ngram=3\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1OmOrzBt70Y-","executionInfo":{"status":"ok","timestamp":1620006331334,"user_tz":300,"elapsed":183,"user":{"displayName":"Diya Li","photoUrl":"","userId":"02479113133044853042"}}},"source":["import numpy as np\n","import copy\n","import signal\n","import json\n","from os.path import isfile\n"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"ycYzAtn9AK4h","executionInfo":{"status":"ok","timestamp":1620007230343,"user_tz":300,"elapsed":344,"user":{"displayName":"Diya Li","photoUrl":"","userId":"02479113133044853042"}}},"source":["import torch\n","\n","from torch.autograd import backward\n","\n","from parlai.core.worlds import MultiAgentDialogWorld\n","from collections import namedtuple\n","from itertools import chain\n","\n","Action = namedtuple('Action', ['id', 'action', 'responses'])\n","\"\"\"\n","A node in the action-response tree.\n",":param id: str, the id of the actor.\n",":param action: dict, containing the agent actions.\n",":param responses: dict, containing the agent's response for the action.\n","\"\"\"\n","\n","ACTIVE, STATIC = 'active', 'static'\n","\n","DULL_RESPONSES = [\n","    {'labels': \"i do n ' t know .\"},\n","    {'labels': 'why ?'},\n","    {'labels': 'i am sorry .'},\n","    {'labels': 'i see .'}\n","]\n","\n","def calculate_dull_log_prob(resp_batch, agent):\n","    model = agent.model\n","    model.eval()\n","    print(resp_batch)\n","    batch = agent.batchify([\n","        {**resp_batch, \n","        'labels': dull_response['labels'],\n","        'labels_vec': agent._vectorize_text(dull_response['labels'])} for\n","        dull_response in DULL_RESPONSES\n","    ])\n","    out = model(batch.text_vec, ys=batch.label_vec)\n","    # generated response\n","\n","    notnull = batch.label_vec.ne(agent.NULL_IDX)\n","    target_tokens = notnull.long().sum().item()\n","\n","    scores = out[0]\n","    score_view = scores.view(-1, scores.size(-1))\n","    loss = agent.criterion(score_view, batch.label_vec.view(-1))\n","    loss = loss.sum().data.cpu().numpy() / target_tokens / len(DULL_RESPONSES)\n","\n","    return loss\n","\n","class RLDialogWorld(MultiAgentDialogWorld):\n","\n","    def __init__(self, opt, active_agent, static_agent, \n","                 teacher, shared=None):\n","        \"\"\"\"\"\"\n","        self.id = 'RLDialogWorld'\n","        self.episode_batch = None\n","        self.active_agent = active_agent\n","        self.static_agent = static_agent\n","        agents = teacher + [static_agent, active_agent]\n","\n","        super(RLDialogWorld, self).__init__(opt, agents, shared)\n","\n","    def parley(self):\n","        \"\"\"\"\"\"\n","        # Initial sentence from the dataset\n","        initial_action = self.agents[0].act()\n","\n","        self.active_agent.zero_grad()\n","        actions = self.rollout(initial_action)\n","\n","        with torch.no_grad():\n","            reward = self.calculate_reward(actions, 1)\n","\n","        self.active_agent.observe({'reward': reward})\n","        self.active_agent.update_params()\n","\n","    def iterate_reponses(self, action):\n","        \"\"\"\"\"\"\n","        for response in action.responses:\n","            yield {\n","                'text': action.action['text'], \n","                'text_vec': action.action['text_vec'].cpu(), \n","                'labels': response.action['text'],\n","                'labels_vec': response.action.get('text_vec', \n","                    self.static_agent._vectorize_text(\n","                        response.action['text']).cpu())\n","            }\n","\n","    def calculate_reward(self, action, weight):\n","        \"\"\"\"\"\"\n","        reward = 0\n","\n","        if len(action.responses) == 0:\n","            return 0\n","\n","        if action.id == ACTIVE:\n","            for resp in self.iterate_reponses(action):\n","                batch = self.active_agent.batchify([resp])\n","\n","                log_prob = self.static_agent.compute_log_prob(batch, False)\n","\n","                reward += log_prob - calculate_dull_log_prob(\n","                    resp, self.static_agent)\n","\n","        # Reduce reward significance for next dialogue turns\n","        weight = weight * self.opt['reward_decay']\n","        for response in action.responses:\n","            reward += self.calculate_reward(response, weight)\n","           \n","        return reward\n","    \n","    def rollout(self, initial_action):\n","        \"\"\"\"\"\"\n","        def roll(action, num_rollouts):\n","            \"\"\"\"\"\"\n","            if action.id == ACTIVE:\n","                self.static_agent.observe(action.action)\n","                act = self.static_agent.act()\n","                act['text_vec'] = act['text_vec'].cpu()\n","                static_action = Action(\n","                    id=STATIC, \n","                    action=act, \n","                    responses=[])\n","\n","                action.responses.append(\n","                    roll(static_action, num_rollouts))\n","\n","            else:\n","                if num_rollouts == 0:\n","                    return action\n","\n","                self.active_agent.observe(action.action)\n","                for _ in range(self.opt['dialog_branches']):\n","                    act = self.active_agent.act()\n","                    act['text_vec'] = act['text_vec'].cpu()\n","                    active_action = Action(\n","                        id=ACTIVE,\n","                        action=act, \n","                        responses=[])\n","\n","                    action.responses.append(\n","                        roll(active_action, num_rollouts - 1))\n","\n","            return action\n","\n","        initial = Action(STATIC, initial_action, [])\n","\n","        return roll(initial, self.opt['dialog_rounds'])"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KduYHRuuRR-_","executionInfo":{"status":"ok","timestamp":1620013403579,"user_tz":300,"elapsed":5613,"user":{"displayName":"Diya Li","photoUrl":"","userId":"02479113133044853042"}},"outputId":"42470336-416f-4dd6-9661-48f182645b71"},"source":["from parlai.scripts.display_model import setup_args, DisplayModel\n","from parlai.core.params import ParlaiParser\n","from parlai.core.script import ParlaiScript, register_script\n","from parlai.core.agents import create_agent\n","from parlai.core.worlds import create_task\n","\n","import random\n","\n","def display_model(opt):\n","    random.seed(42)\n","\n","    # Create model and assign it to the specified task\n","    agent = create_agent(opt)\n","    world = create_task(opt, agent)\n","\n","    return agent, world\n","\n","@register_script('display_model', aliases=['dm'])\n","class GetPretrainedAgent(ParlaiScript):\n","    @classmethod\n","    def setup_args(cls):\n","        return setup_args()\n","\n","    def run(self):\n","        return display_model(self.opt)\n","\n","agent, world = GetPretrainedAgent.main(\n","    task='empathetic_dialogues',\n","    model_file=os.path.join(working_dir, \"from_pretrained/model\"),\n","    num_examples=5,\n","    skip_generation=False,\n",")"],"execution_count":21,"outputs":[{"output_type":"stream","text":["03:43:18 | \u001b[33mOverriding opt[\"model_file\"] to /content/drive/MyDrive/Dev/ECEN689/ECEN689/from_pretrained/model (previously: from_pretrained/model)\u001b[0m\n","03:43:18 | \u001b[33mOverriding opt[\"skip_generation\"] to False (previously: True)\u001b[0m\n","03:43:18 | Using CUDA\n","03:43:18 | loading dictionary from /content/drive/MyDrive/Dev/ECEN689/ECEN689/from_pretrained/model.dict\n","03:43:18 | num words = 54944\n","03:43:20 | Total parameters: 87,508,992 (87,508,992 trainable)\n","03:43:20 | Loading existing model params from /content/drive/MyDrive/Dev/ECEN689/ECEN689/from_pretrained/model\n","03:43:23 | creating task(s): empathetic_dialogues\n","[EmpatheticDialoguesTeacher] Only use experiencer side? True, datatype: valid\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wVCI92pxcEvf","executionInfo":{"status":"ok","timestamp":1620014055101,"user_tz":300,"elapsed":499,"user":{"displayName":"Diya Li","photoUrl":"","userId":"02479113133044853042"}}},"source":["from parlai.core.agents import register_agent, Agent\n","from parlai.core.opt import Opt\n","\n","# from parlai.agents.transformer import add_common_cmdline_args\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from typing import Optional\n","\n","@register_agent(\"RLTorchGeneratorAgent\")\n","class RLTorchGeneratorAgent(agent.__class__):\n","\n","    @classmethod\n","    def add_cmdline_args(\n","        cls, parser: ParlaiParser, partial_opt: Optional[Opt] = None\n","    ) -> ParlaiParser:\n","        \"\"\"\n","        Add command-line arguments specifically for this agent.\n","        \"\"\"\n","        agent = parser.add_argument_group('Transformer Arguments')\n","        # add_common_cmdline_args(agent)\n","        cls.dictionary_class().add_cmdline_args(parser, partial_opt=partial_opt)\n","\n","        super().add_cmdline_args(parser, partial_opt=partial_opt)\n","        return agent\n","\n","    @torch.no_grad()\n","    def sample_step(self, batch):\n","        \"\"\"\n","        Sample a single batch of examples which will be used as \n","        labels for the train step.\n","        \"\"\"\n","        self.model.eval()\n","\n","        _, preds, _ = self.model(\n","            *self._model_input(batch), ys=batch.label_vec, \n","            use_probabilistic_decode=True)\n","\n","        self.add_labels(batch, preds)\n","\n","        return batch\n","\n","    def add_labels(self, batch, label_vecs):\n","        \"\"\"\"\"\"\n","        labels = [self._v2t(l) for l in label_vecs]\n","        ys, y_lens = padded_tensor(\n","            label_vecs, self.NULL_IDX, self.use_cuda)\n","            \n","        batch.labels=labels\n","        batch.label_vec=ys\n","        batch.label_lengths=y_lens\n","\n","    def compute_log_prob(self, batch, track_metrics=True):\n","        \"\"\"\"\"\"\n","        if batch.label_vec is None:\n","            raise ValueError('Cannot compute loss without a label.')\n","\n","        model_output = self.model(\n","            *self._model_input(batch), ys=batch.label_vec)\n","        scores, preds, *_ = model_output\n","        score_view = scores.view(-1, scores.size(-1))\n","        log_prob = self.criterion(score_view, batch.label_vec.view(-1))\n","\n","        notnull = batch.label_vec.ne(self.NULL_IDX)\n","        target_tokens = notnull.long().sum().item()\n","        correct = ((batch.label_vec == preds) * notnull).sum().item()\n","\n","        if track_metrics:\n","            self.metrics['correct_tokens'] += correct\n","            self.metrics['nll_loss'] += log_prob.item()\n","            self.metrics['num_tokens'] += target_tokens\n","\n","        log_prob /= target_tokens  # average loss per token\n","\n","        return log_prob\n","\n","    def train_step(self, batch):\n","        \"\"\"\n","        Train on a single batch of examples.\n","        \"\"\"\n","        try:\n","            batch = self.sample_step(batch)\n","            log_prob = self.compute_log_prob(batch)\n","            self.metrics['loss'] += log_prob.item()\n","            self.log_probs.append(log_prob)\n","\n","        except RuntimeError as e:\n","            if 'out of memory' in str(e):\n","                print('| WARNING: ran out of memory, skipping batch. ')\n","                self.metrics['total_skipped_batches'] += 1\n","                # gradients are synced on backward, \n","                # now this model is going to be\n","                # out of sync! catch up with the other workers\n","                self._init_cuda_buffer(8, 8, True)\n","            else:\n","                raise e\n","        \n","        return Output(\n","            text=batch.labels,\n","            text_vec=batch.label_vec,\n","            text_candidates=None)\n","        \n","    def observe(self, observation):\n","        \"\"\"\n","        Calculates the reward and copies the model if provided\n","        additionally to the ``super().observe()``.\n","        \"\"\"\n","        if observation.get('reward') is not None:\n","            reward = observation['reward']\n","            for log_prob in self.log_probs:\n","                loss = - log_prob * reward\n","                self.backward(loss)\n","            \n","            self.log_probs = []\n","\n","            for parameter in self.model.parameters():  # pylint: disable=access-member-before-definition\n","                if parameter.grad is not None:\n","                    parameter.grad.data.clamp_(min=-5, max=5)\n","            \n","        if observation.get('model') is not None:\n","            # Deepcopied and frozen clone of the model\n","            self.model = observation['model']\n","\n","        return super(RLTorchGeneratorAgent, self).observe(\n","            observation)\n","        \n","    def match_batch(self, batch_reply, valid_inds, output=None):\n","        \"\"\"\"\"\"\n","        batch_reply = super(RLTorchGeneratorAgent, self).match_batch(\n","            batch_reply, valid_inds, output)\n","\n","        if getattr(output, 'text_vec', None) is not None:\n","            for idx, val_idx in enumerate(valid_inds):\n","                batch_reply[val_idx]['text_vec'] = output.text_vec[idx]\n","        \n","        return batch_reply\n","        \n","    def build_model(self, *args, **kwargs):\n","        super(RLTorchGeneratorAgent, self).build_model(\n","            *args, **kwargs)\n","        assert model is not None, ('Model must be initialized first')\n","        model.forward = forward.__get__(model)\n","        \n","    # def build_model(self):\n","    #     model = MyModel\n"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"RKGlbs53bmnz","executionInfo":{"status":"ok","timestamp":1620007382531,"user_tz":300,"elapsed":193,"user":{"displayName":"Diya Li","photoUrl":"","userId":"02479113133044853042"}}},"source":["def get_agent_type(opt):\n","    model_file = opt.get(\"model_file\")\n","    optfile = model_file + '.opt'\n","    if isfile(optfile):\n","        new_opt = Opt.load(optfile)\n","        print(new_opt)            \n","\n","def create_agent(opt):\n","    \"\"\"\n","    Creates a new class, that extends the provided \n","    subclass of ``TorchGeneratorAgent`` with reinforcement\n","    learning functionality.\n","    \"\"\"\n","    torch_generator_agent_subclass = get_agent_type(opt)"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"TGqIWQTIlwY6","executionInfo":{"status":"ok","timestamp":1620007435989,"user_tz":300,"elapsed":321,"user":{"displayName":"Diya Li","photoUrl":"","userId":"02479113133044853042"}}},"source":["from parlai.scripts.train_model import setup_args, TrainLoop\n","from parlai.scripts.build_dict import build_dict\n","\n","def get_opt():\n","    parser = setup_args()\n","    reinforce = parser.add_argument_group('Reinforce Arguments')\n","    reinforce.add_argument('--dialog_rounds',type=int, default=2) # Number of rollouts rounds for estimating the reward.\n","    reinforce.add_argument('--dialog_branches', type=int, default=5) # Branches of the active agent responses during rollout.\n","    reinforce.add_argument('--language_model_path',type=str,default=os.path.join(working_dir, \"from_pretrained/model\"))\n","    reinforce.add_argument('--reward_decay',type=float,default=0.9)\n","    reinforce.add_argument('--model_file',type=str, default=os.path.join(working_dir, \"from_pretrained/model\") )\n","    return parser.parse_args(\"\")\n","\n","class RLLoop(TrainLoop):\n","    def __init__(self, opt):\n","        signal.signal(signal.SIGINT, signal.default_int_handler)\n","\n","        # training statistic checkpoint\n","        trainstats_suffix = \".trainstats\"\n","        if opt.get('model_file') and isfile(opt['model_file'] + '.checkpoint'):\n","            trainstats_suffix = \".checkpoint.trainstats\"\n","        \n","        self.agent = create_agent(opt)\n","        \n","\n","opt = get_opt()"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"amTWmc9UmI3i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620013600738,"user_tz":300,"elapsed":2116,"user":{"displayName":"Diya Li","photoUrl":"","userId":"02479113133044853042"}},"outputId":"615f0872-d5ca-43d2-ba23-9a26bd05fb8e"},"source":["DisplayModel.main(\n","    task='empathetic_dialogues', model='RLTorchGeneratorAgent', \n","    skip_generation=True,\n",")"],"execution_count":29,"outputs":[{"output_type":"stream","text":["03:46:39 | Using CUDA\n","03:46:39 | Total parameters: 3,511,200 (2,896,800 trainable)\n","03:46:39 | creating task(s): empathetic_dialogues\n","[EmpatheticDialoguesTeacher] Only use experiencer side? True, datatype: valid\n","03:46:40 | Opt:\n","03:46:40 |     activation: relu\n","03:46:40 |     adafactor_eps: '(1e-30, 0.001)'\n","03:46:40 |     adam_eps: 1e-08\n","03:46:40 |     add_p1_after_newln: False\n","03:46:40 |     allow_missing_init_opts: False\n","03:46:40 |     attention_dropout: 0.0\n","03:46:40 |     batchsize: 1\n","03:46:40 |     beam_block_full_context: True\n","03:46:40 |     beam_block_list_filename: None\n","03:46:40 |     beam_block_ngram: -1\n","03:46:40 |     beam_context_block_ngram: -1\n","03:46:40 |     beam_delay: 30\n","03:46:40 |     beam_length_penalty: 0.65\n","03:46:40 |     beam_min_length: 1\n","03:46:40 |     beam_size: 1\n","03:46:40 |     betas: '(0.9, 0.999)'\n","03:46:40 |     bpe_add_prefix_space: None\n","03:46:40 |     bpe_debug: False\n","03:46:40 |     bpe_dropout: None\n","03:46:40 |     bpe_merge: None\n","03:46:40 |     bpe_vocab: None\n","03:46:40 |     compute_tokenized_bleu: False\n","03:46:40 |     datapath: /usr/local/lib/python3.7/dist-packages/data\n","03:46:40 |     datatype: valid\n","03:46:40 |     delimiter: '\\n'\n","03:46:40 |     dict_class: parlai.core.dict:DictionaryAgent\n","03:46:40 |     dict_endtoken: __end__\n","03:46:40 |     dict_file: None\n","03:46:40 |     dict_initpath: None\n","03:46:40 |     dict_language: english\n","03:46:40 |     dict_loaded: False\n","03:46:40 |     dict_lower: False\n","03:46:40 |     dict_max_ngram_size: -1\n","03:46:40 |     dict_maxtokens: -1\n","03:46:40 |     dict_minfreq: 0\n","03:46:40 |     dict_nulltoken: __null__\n","03:46:40 |     dict_starttoken: __start__\n","03:46:40 |     dict_textfields: text,labels\n","03:46:40 |     dict_tokenizer: re\n","03:46:40 |     dict_unktoken: __unk__\n","03:46:40 |     display_add_fields: \n","03:46:40 |     download_path: None\n","03:46:40 |     dropout: 0.0\n","03:46:40 |     dynamic_batching: None\n","03:46:40 |     embedding_projection: random\n","03:46:40 |     embedding_size: 300\n","03:46:40 |     embedding_type: random\n","03:46:40 |     embeddings_scale: True\n","03:46:40 |     ffn_size: 300\n","03:46:40 |     force_fp16_tokens: False\n","03:46:40 |     fp16: False\n","03:46:40 |     fp16_impl: safe\n","03:46:40 |     gpu: -1\n","03:46:40 |     gradient_clip: 0.1\n","03:46:40 |     hide_labels: False\n","03:46:40 |     history_add_global_end_token: None\n","03:46:40 |     history_reversed: False\n","03:46:40 |     history_size: -1\n","03:46:40 |     image_cropsize: 224\n","03:46:40 |     image_mode: raw\n","03:46:40 |     image_size: 256\n","03:46:40 |     inference: greedy\n","03:46:40 |     init_model: None\n","03:46:40 |     init_opt: None\n","03:46:40 |     interactive_mode: False\n","03:46:40 |     invsqrt_lr_decay_gamma: -1\n","03:46:40 |     is_debug: False\n","03:46:40 |     label_truncate: None\n","03:46:40 |     learn_positional_embeddings: False\n","03:46:40 |     learningrate: 1\n","03:46:40 |     loglevel: info\n","03:46:40 |     lr_scheduler: reduceonplateau\n","03:46:40 |     lr_scheduler_decay: 0.5\n","03:46:40 |     lr_scheduler_patience: 3\n","03:46:40 |     model: RLAgent\n","03:46:40 |     model_file: None\n","03:46:40 |     model_parallel: False\n","03:46:40 |     momentum: 0\n","03:46:40 |     multitask_weights: [1]\n","03:46:40 |     mutators: None\n","03:46:40 |     n_decoder_layers: -1\n","03:46:40 |     n_encoder_layers: -1\n","03:46:40 |     n_heads: 2\n","03:46:40 |     n_layers: 2\n","03:46:40 |     n_positions: None\n","03:46:40 |     n_segments: 0\n","03:46:40 |     nesterov: True\n","03:46:40 |     no_cuda: False\n","03:46:40 |     num_examples: 10\n","03:46:40 |     nus: (0.7,)\n","03:46:40 |     optimizer: sgd\n","03:46:40 |     output_scaling: 1.0\n","03:46:40 |     override: \"{'task': 'empathetic_dialogues', 'model': 'RLAgent', 'skip_generation': True}\"\n","03:46:40 |     parlai_home: /usr/local/lib/python3.7/dist-packages\n","03:46:40 |     person_tokens: False\n","03:46:40 |     rank_candidates: False\n","03:46:40 |     relu_dropout: 0.0\n","03:46:40 |     remove_political_convos: False\n","03:46:40 |     share_word_embeddings: True\n","03:46:40 |     skip_generation: True\n","03:46:40 |     special_tok_lst: None\n","03:46:40 |     split_lines: False\n","03:46:40 |     starttime: May03_03-46\n","03:46:40 |     task: empathetic_dialogues\n","03:46:40 |     temperature: 1.0\n","03:46:40 |     text_truncate: None\n","03:46:40 |     topk: 10\n","03:46:40 |     topp: 0.9\n","03:46:40 |     train_experiencer_only: False\n","03:46:40 |     truncate: -1\n","03:46:40 |     update_freq: 1\n","03:46:40 |     use_reply: label\n","03:46:40 |     variant: aiayn\n","03:46:40 |     verbose: False\n","03:46:40 |     warmup_rate: 0.0001\n","03:46:40 |     warmup_updates: -1\n","03:46:40 |     weight_decay: None\n","03:46:40 | \u001b[33m--skip-generation true produces limited metrics\u001b[0m\n","\u001b[1;31m- - - NEW EPISODE: empathetic_dialogues- - -\u001b[0;0m\n","\u001b[0mToday,as i was leaving for work in the morning,i had a tire burst in the middle of a busy road. That scared the hell out of me!\u001b[0;0m\n","\u001b[1;94m    labels: Are you fine now?\u001b[0;0m\n","\u001b[0;95m     model: No response\u001b[0;0m\n","\u001b[0mYeah,i'm doing alright now, but with minor injuries.\u001b[0;0m\n","\u001b[1;94m    labels: Cool :) Is your car damaged a lot?\u001b[0;0m\n","\u001b[0;95m     model: No response\u001b[0;0m\n","\u001b[1;31m- - - NEW EPISODE: empathetic_dialogues- - -\u001b[0;0m\n","\u001b[0mA few weeks ago, I was walking through my hallway, minding my own business, when all of a sudden a hand reached out from under a table and grabbed my ankle. I was so suprised. I thought i was got. Turns out, it was my son. \u001b[0;0m\n","\u001b[1;94m    labels: That's funny, hope he didn't give you a heart attack.\u001b[0;0m\n","\u001b[0;95m     model: No response\u001b[0;0m\n","\u001b[0mI may have let out a scream that will have him question my manhood for the rest of our lives, lol. \u001b[0;0m\n","\u001b[1;94m    labels: I would probably scream also.\u001b[0;0m\n","\u001b[0;95m     model: No response\u001b[0;0m\n","\u001b[1;31m- - - NEW EPISODE: empathetic_dialogues- - -\u001b[0;0m\n","\u001b[0mI'm overly excited because will be flying outside the country for the first time tomorrow.\".  Please enter here...\u001b[0;0m\n","\u001b[1;94m    labels: Wow! That sounds amazing. Where are you going? \u001b[0;0m\n","\u001b[0;95m     model: No response\u001b[0;0m\n","\u001b[0mTraveling to South Africa then to Ghana. Also my first time visiting Africa\u001b[0;0m\n","\u001b[1;94m    labels: You are going to love it I am sure. Safe Travels! \u001b[0;0m\n","\u001b[0;95m     model: No response\u001b[0;0m\n","\u001b[1;31m- - - NEW EPISODE: empathetic_dialogues- - -\u001b[0;0m\n","\u001b[0mOne time, I was holding my son over my head, when all of a sudden, he threw up all over my face. I almost cried.\u001b[0;0m\n","\u001b[1;94m    labels: Thats horrible, hope he is ok.\u001b[0;0m\n","\u001b[0;95m     model: No response\u001b[0;0m\n","\u001b[0myeah, he had just drank a bottle, and I was moving him around like an airplane. In retrospect. I deserved it.\u001b[0;0m\n","\u001b[1;94m    labels: I see, glad he is ok.\u001b[0;0m\n","\u001b[0;95m     model: No response\u001b[0;0m\n","\u001b[1;31m- - - NEW EPISODE: empathetic_dialogues- - -\u001b[0;0m\n","\u001b[0mHello\u001b[0;0m\n","\u001b[1;94m    labels: Hi, how are you?\u001b[0;0m\n","\u001b[0;95m     model: No response\u001b[0;0m\n","\u001b[0mIm doing great i just wanted to tell you a short story about a time i helped an elderly lady.  She was struggling to carry her bags from a trip she had took.  I helped her carry them to her door ! Pretty good feeling when you help others \u001b[0;0m\n","\u001b[1;94m    labels: That was kind of you, I am sure they appreciated that!\u001b[0;0m\n","\u001b[0;95m     model: No response\u001b[0;0m\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dQsZybfwr6Yb","executionInfo":{"status":"ok","timestamp":1619984996162,"user_tz":300,"elapsed":412,"user":{"displayName":"Diya Li","photoUrl":"","userId":"02479113133044853042"}}},"source":["opt.get(\"model_file\")"],"execution_count":46,"outputs":[]},{"cell_type":"code","metadata":{"id":"0gyFFylrr-Y7"},"source":[""],"execution_count":null,"outputs":[]}]}